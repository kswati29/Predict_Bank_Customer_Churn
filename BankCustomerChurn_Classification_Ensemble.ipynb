{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "This churn modeling notebook is associated with focused customer retention programs, i.e. predict behavior to retain customers and uses a bank's churning dataset to build a classifier for predicting customer churn. The data set is obtained from Kaggle [here](https://www.kaggle.com/shrutimechlearn/churn-modelling). The goal is to predict whether a bank customer will churn or not, that is, whether the customer will leave the bank (close account) or continue to be a customer given customer details. \n",
    "\n",
    "For this task, different ensemble methods are compared for the binary classification modeling. An ensemble is a composite modeling that combines few low performing classifiers to create an improved classifier.\n",
    "In particular the models employed are:\n",
    "1. Voting (Hard and Soft)\n",
    "2. Bagging\n",
    "3. Boosting (AdaBoost, XGBoost, LightGBM)\n",
    "4. Stacking\n",
    "\n",
    "The performance metrics used is accuracy.\n",
    "\n",
    "#### Let's load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "data = pd.read_csv('bank_churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, some preprocessing. Remove the columns: RowNumber, CustomerID, Surname. Convert categorical data into dummy variables (with dropping). Split data into 80%-20% train/test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0             619   42       2       0.00              1          1   \n",
       "1             608   41       1   83807.86              1          0   \n",
       "2             502   42       8  159660.80              3          1   \n",
       "3             699   39       1       0.00              2          0   \n",
       "4             850   43       2  125510.82              1          1   \n",
       "...           ...  ...     ...        ...            ...        ...   \n",
       "9995          771   39       5       0.00              2          1   \n",
       "9996          516   35      10   57369.61              1          1   \n",
       "9997          709   36       7       0.00              1          0   \n",
       "9998          772   42       3   75075.31              2          1   \n",
       "9999          792   28       4  130142.79              1          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Exited  Geography_Germany  \\\n",
       "0                  1        101348.88       1                  0   \n",
       "1                  1        112542.58       0                  0   \n",
       "2                  0        113931.57       1                  0   \n",
       "3                  0         93826.63       0                  0   \n",
       "4                  1         79084.10       0                  0   \n",
       "...              ...              ...     ...                ...   \n",
       "9995               0         96270.64       0                  0   \n",
       "9996               1        101699.77       0                  0   \n",
       "9997               1         42085.58       1                  0   \n",
       "9998               0         92888.52       1                  1   \n",
       "9999               0         38190.78       0                  0   \n",
       "\n",
       "      Geography_Spain  Gender_Male  \n",
       "0                   0            0  \n",
       "1                   1            0  \n",
       "2                   0            0  \n",
       "3                   0            0  \n",
       "4                   1            0  \n",
       "...               ...          ...  \n",
       "9995                0            1  \n",
       "9996                0            1  \n",
       "9997                0            0  \n",
       "9998                0            1  \n",
       "9999                0            0  \n",
       "\n",
       "[10000 rows x 12 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove columns\n",
    "data.drop(['RowNumber', 'CustomerId', 'Surname'], axis = 1, inplace = True)\n",
    "\n",
    "# Create dummy variables\n",
    "data = pd.get_dummies(data = data, columns = ['Geography','Gender'], drop_first = True)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract X and y, split into train test and scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract X and y\n",
    "X = data.drop('Exited', axis = 1)\n",
    "y = data.Exited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split to 80-20\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 862)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_trainS = scaler.fit_transform(X_train)\n",
    "X_testS = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Modeling with Ensemble Methods\n",
    "Let's build an ensemble classifier using each method, and provide evaluation (accuracy) on the test set. Also, we will conduct the appropriate preprocessing (if needed) and further hyperparameter tuning for some."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting (Soft) Classifier\n",
    "Let's build a soft voting classifier.\n",
    "Using 5 classifiers, where two of them are same but with different hyperparameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Logistic, RandomForest and Boosting classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the individual models\n",
    "\n",
    "clf1 = LogisticRegression(penalty = 'none',random_state=1) # Unregularized\n",
    "clf2 = LogisticRegression(penalty = 'l1', solver = 'liblinear', random_state=1) # Regularized\n",
    "clf3 = RandomForestClassifier(random_state=1)\n",
    "clf4 = GradientBoostingClassifier(random_state=1)\n",
    "clf5 = KNeighborsClassifier()\n",
    "\n",
    "eclf_soft = VotingClassifier(estimators=[('lr1', clf1),('lr2',clf2),('rf',clf3),('gb',clf4),('knn',clf5)], voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soft Voting: 0.85\n"
     ]
    }
   ],
   "source": [
    "# Set up parameter set for differnet weak learners\n",
    "param = [{'lr1__solver':['lbfgs','newton-cg'],\n",
    "          \n",
    "          'lr2__C':np.logspace(-10, 10, 5),\n",
    "          \n",
    "          'rf__n_estimators':np.linspace(100, 1000, 5, dtype = int),\n",
    "                    \n",
    "          'gb__learning_rate':[0.01,0.1],\n",
    "          \n",
    "          'knn__n_neighbors': [5,10],\n",
    "          'knn__p': [1,2] }]\n",
    "\n",
    "\n",
    "grid = GridSearchCV(estimator = eclf_soft, param_grid = param, cv=2, n_jobs=-2, scoring='accuracy')\n",
    "\n",
    "# Fit the voting classifier\n",
    "grid.fit(X_trainS, y_train)\n",
    "y_pred = grid.predict(X_testS)\n",
    "\n",
    "# Perform prediction on the fitted voting classifier\n",
    "print('Soft Voting:',np.mean(grid.predict(X_testS) == y_test))\n",
    "\n",
    "# https://stats.stackexchange.com/questions/320156/hard-voting-versus-soft-voting-in-ensemble-based-methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting (Hard) Classifier\n",
    "Now let's do the same, but with a hard voting classifier and we will later compare the result with the soft classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard Voting: 0.84\n"
     ]
    }
   ],
   "source": [
    "# Use as many boxes as you need\n",
    "eclf_hard = VotingClassifier(estimators=[('lr1', clf1),('lr2',clf2),('rf',clf3),('gb',clf4),('knn',clf5)], voting='hard')\n",
    "\n",
    "grid_h = GridSearchCV(estimator = eclf_hard, param_grid = param, cv=2, n_jobs=-2, scoring='accuracy')\n",
    "\n",
    "# Fit the voting classifier\n",
    "grid_h.fit(X_trainS, y_train)\n",
    "y_pred = grid_h.predict(X_testS)\n",
    "\n",
    "# Perform prediction on the fitted voting classifier\n",
    "print('Hard Voting:',np.mean(grid_h.predict(X_testS) == y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:** Soft Voting gave a little better score of 0.85 accuracy than hard voting with 0.84."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a comparison, let's also fit the individual models and see if there's really an improvement with the voting classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>params</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF</td>\n",
       "      <td>{'n_estimators': 775}</td>\n",
       "      <td>0.8535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GB</td>\n",
       "      <td>{'learning_rate': 0.1}</td>\n",
       "      <td>0.8525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>{'n_neighbors': 10, 'p': 1}</td>\n",
       "      <td>0.8280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LR2_reg</td>\n",
       "      <td>{'C': 1.0}</td>\n",
       "      <td>0.8035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LR1_unreg</td>\n",
       "      <td>{'solver': 'lbfgs'}</td>\n",
       "      <td>0.8030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  classifier                       params   score\n",
       "0         RF        {'n_estimators': 775}  0.8535\n",
       "1         GB       {'learning_rate': 0.1}  0.8525\n",
       "2        KNN  {'n_neighbors': 10, 'p': 1}  0.8280\n",
       "3    LR2_reg                   {'C': 1.0}  0.8035\n",
       "4  LR1_unreg          {'solver': 'lbfgs'}  0.8030"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Set up the names and estimators selected in a list\n",
    "\n",
    "names = ['LR1_unreg','LR2_reg','RF','GB','KNN']\n",
    "\n",
    "classifiers = [LogisticRegression(penalty = 'none',random_state=1),\n",
    "               LogisticRegression(penalty = 'l1', solver = 'liblinear', random_state=1),\n",
    "               RandomForestClassifier(random_state=1),\n",
    "               GradientBoostingClassifier(random_state=1),\n",
    "               KNeighborsClassifier()]\n",
    "\n",
    "parameters = [ {'solver':['lbfgs','newton-cg']},\n",
    "              {'C':np.logspace(-10, 10, 5)},\n",
    "              {'n_estimators':np.linspace(100, 1000, 5, dtype = int)},\n",
    "              {'learning_rate':[0.01,0.1]}, \n",
    "              {'n_neighbors': [5,10],'p': [1,2]} ]\n",
    "\n",
    "\n",
    "result =[] # empty list to store accuracy score\n",
    "best_params = [] #empty list to store best parameters\n",
    "\n",
    "# 2. Loop to Instantiate gridsearch cross validation and fit for the model in pipeline\n",
    "for name, classifier, params in zip(names, classifiers, parameters):\n",
    "    \n",
    "    grid = GridSearchCV(estimator = classifier, param_grid = params, cv=2, n_jobs=-2, scoring='accuracy')\n",
    "    grid.fit(X_trainS, y_train)\n",
    "\n",
    "    result.append(accuracy_score(y_test,grid.predict(X_testS)))\n",
    "    best_params.append(grid.best_params_)\n",
    "    \n",
    "    \n",
    "# 3. Ranked order of classifiers based on accuracy\n",
    "data_features = sorted(list(zip(names,best_params,result)), key = lambda x: x[2], reverse = True)\n",
    "pd.DataFrame(data_features, columns = ['classifier','params','score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:** Random Forest (0.8535) and Gradient Boosting (0.8525) classifiers gave a little better scoring than both soft and hard voting classifiers. Interestingly, the voting didn't outperform all models even after tuning. Perhaps more tuning could improve results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagged Logistic Regression\n",
    "It is also called Bootstrap Aggregating and helps reduce little bias and variance. It works as training all classifiers and then the ensemble makes prediction by aggregating results from all classifiers usually through majority vote. Weak learners can be trained parallelly, making it efficient.\n",
    "Random Forest is an example of bagging. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagged: 0.8035\n"
     ]
    }
   ],
   "source": [
    "# Use as many boxes as you need\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# Instantiate the model\n",
    "bag_clf = BaggingClassifier(LogisticRegression(penalty = 'l1', solver = 'liblinear', random_state=1), \n",
    "                           n_estimators = 100)\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "bag_clf.fit(X_trainS, y_train)\n",
    "\n",
    "# Prediction\n",
    "print('Bagged:',np.mean(bag_clf.predict(X_testS) == y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:**  Bagged Logistic Regression gives a low score and is lower than voting classifier. Hyperparameter tuning could result in a better score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting\n",
    "Based on the principle of training models sequentially, each trying to correct its predecessor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost\n",
    "Ada Boosting is adaptive Boosting. The concept is that instead of modeling the residual, model the data at each round, but\n",
    "assign weights to observations. Misclassified observations will be focused more during training, to improve error. Each learner will be assigned a weight as well, based on the errors it makes based on the learning rate. \n",
    "AdaBoost is sensitive to noisy data and outliers because it tries to fit each point.\n",
    "\n",
    "If base estimator is None, then the base estimator is DecisionTreeClassifier initialized with max_depth=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'base_estimator': None, 'learning_rate': 0.1, 'n_estimators': 100}\n",
      "Accuracy tuned XGB 0.8455\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# With parameter tuning\n",
    "\n",
    "# Instantiate the model\n",
    "adabc = AdaBoostClassifier(random_state = 1)\n",
    "\n",
    "adabc_param = {'n_estimators': [10,50,100],\n",
    "    'base_estimator': [None,LogisticRegression(),SVC(probability=True, kernel='linear')], #DecisionTreeClassifier(max_depth=5)\n",
    "    'learning_rate': [0.1,1]}\n",
    "\n",
    "adabc_grid = GridSearchCV(estimator=adabc, param_grid=adabc_param, cv = 2, scoring = 'accuracy', n_jobs = -2)\n",
    "\n",
    "# Fit the model\n",
    "adabc_grid.fit(X_trainS, y_train)\n",
    "# rmse for regression, and logloss for classification, mean average precision for ranking\n",
    "\n",
    "# Prediction\n",
    "print(\"Best params:\",adabc_grid.best_params_)\n",
    "print(\"Accuracy tuned XGB\",np.mean(adabc_grid.predict(X_testS) == y_test))\n",
    "\n",
    "# https://www.kaggle.com/prashant111/adaboost-classifier-tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost\n",
    "Similar to Gradient Boosting but much more efficient and improved in terms of regularization,parallel processing, handling missing values and early stopping. It uses decision trees as base learners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split model to get a validation set\n",
    "X_t, X_valid, y_t, y_valid = train_test_split(X_train, y_train, test_size = 0.25, random_state = 1) \n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_tS = scaler.fit_transform(X_t)\n",
    "X_vS = scaler.transform(X_valid)\n",
    "X_teS = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Swati\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\dask\\dataframe\\utils.py:14: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.16150\n",
      "Will train until validation_0-error hasn't improved in 5 rounds.\n",
      "[1]\tvalidation_0-error:0.15700\n",
      "[2]\tvalidation_0-error:0.15900\n",
      "[3]\tvalidation_0-error:0.15950\n",
      "[4]\tvalidation_0-error:0.14600\n",
      "[5]\tvalidation_0-error:0.14600\n",
      "[6]\tvalidation_0-error:0.14600\n",
      "[7]\tvalidation_0-error:0.14500\n",
      "[8]\tvalidation_0-error:0.14500\n",
      "[9]\tvalidation_0-error:0.14500\n",
      "[10]\tvalidation_0-error:0.14500\n",
      "[11]\tvalidation_0-error:0.14450\n",
      "[12]\tvalidation_0-error:0.14050\n",
      "[13]\tvalidation_0-error:0.14050\n",
      "[14]\tvalidation_0-error:0.14050\n",
      "[15]\tvalidation_0-error:0.14000\n",
      "[16]\tvalidation_0-error:0.13750\n",
      "[17]\tvalidation_0-error:0.14000\n",
      "[18]\tvalidation_0-error:0.14000\n",
      "[19]\tvalidation_0-error:0.13900\n",
      "[20]\tvalidation_0-error:0.14000\n",
      "[21]\tvalidation_0-error:0.13900\n",
      "Stopping. Best iteration:\n",
      "[16]\tvalidation_0-error:0.13750\n",
      "\n",
      "Accuracy XGB 0.852\n"
     ]
    }
   ],
   "source": [
    "# pip install xgboost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Instantiate the model\n",
    "xgbc = XGBClassifier(objective= 'binary:logistic', n_estimators = 100,\n",
    "                        max_depth = 3, learning_rate = 0.1, n_jobs = -2, random_state = 1)\n",
    "\n",
    "# Fit the model\n",
    "xgbc.fit(X_tS, y_t, eval_set = [(X_vS, y_valid)], \n",
    "            early_stopping_rounds = 5) # Implementing early stopping\n",
    "\n",
    "# Prediction\n",
    "print(\"Accuracy XGB\",np.mean(xgbc.predict(X_teS) == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 500}\n",
      "Accuracy tuned XGB 0.853\n"
     ]
    }
   ],
   "source": [
    "# With parameter tuning\n",
    "\n",
    "# Instantiate the model\n",
    "xgbc = XGBClassifier(objective= 'binary:logistic',random_state = 1)\n",
    "\n",
    "xgbc_param = {'n_estimators': [100,200,500,1000],\n",
    "    'max_depth': [2,3,5,10],\n",
    "    'learning_rate': [0.1, 0.01, 0.05]}\n",
    "\n",
    "xgbc_grid = GridSearchCV(estimator=xgbc, param_grid=xgbc_param, cv = 2, scoring = 'accuracy', n_jobs = -2)\n",
    "\n",
    "# Fit the model\n",
    "xgbc_grid.fit(X_trainS, y_train, eval_metric = 'logloss')\n",
    "# rmse for regression, and logloss for classification, mean average precision for ranking\n",
    "\n",
    "# Prediction\n",
    "print(\"Best params:\",xgbc_grid.best_params_)\n",
    "print(\"Accuracy tuned XGB\",np.mean(xgbc_grid.predict(X_testS) == y_test))\n",
    "\n",
    "# References\n",
    "# https://www.mikulskibartosz.name/xgboost-hyperparameter-tuning-in-python-using-grid-search/\n",
    "# https://github.com/dmlc/xgboost/blob/master/doc/parameter.rst\n",
    "# https://xgboost.readthedocs.io/en/latest/python/python_api.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:** XGBoost gave a comparable score (0.853) with Random Forest Classifier (0.8535) and also is better than the voting classifiers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Light GBM\n",
    "Works well with large data and uses decision trees as base learners.Other algorithms grow the tree as a whole level, while Light GBM grows the tree at the leaf level, hence much faster. Due to producing and handling complex trees, it gives higher accuracy but may overfit data so need to control the maximum depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's auc: 0.854731\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's auc: 0.857237\n",
      "[3]\tvalid_0's auc: 0.860349\n",
      "[4]\tvalid_0's auc: 0.860698\n",
      "[5]\tvalid_0's auc: 0.860753\n",
      "[6]\tvalid_0's auc: 0.864412\n",
      "[7]\tvalid_0's auc: 0.866179\n",
      "[8]\tvalid_0's auc: 0.867591\n",
      "[9]\tvalid_0's auc: 0.867086\n",
      "[10]\tvalid_0's auc: 0.866502\n",
      "[11]\tvalid_0's auc: 0.867104\n",
      "[12]\tvalid_0's auc: 0.866083\n",
      "[13]\tvalid_0's auc: 0.865924\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's auc: 0.867591\n",
      "Accuracy LGBM 0.845\n"
     ]
    }
   ],
   "source": [
    "# pip install lightgbm\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Instantiate the model\n",
    "lgbmc = LGBMClassifier(objective= 'binary', n_estimators = 100, metric = 'auc', num_leaves = 31,\n",
    "                        learning_rate = 0.1, n_jobs = -2, random_state = 1)\n",
    "\n",
    "# Fit the model\n",
    "lgbmc.fit(X_tS, y_t, eval_set = [(X_vS, y_valid)], eval_metric='auc',\n",
    "            early_stopping_rounds = 5) # Implementing early stopping\n",
    "\n",
    "# Prediction\n",
    "print(\"Accuracy LGBM\",np.mean(lgbmc.predict(X_teS) == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "\n",
      "Best params: {'learning_rate': 0.01, 'metric': 'auc', 'min_data_in_leaf': 20, 'n_estimators': 500, 'num_leaves': 10}\n",
      "\n",
      "Accuracy tuned LGBM 0.852\n"
     ]
    }
   ],
   "source": [
    "# Use as many boxes as you need\n",
    "\n",
    "# With parameter tuning\n",
    "\n",
    "# Instantiate the model\n",
    "lgbmc = LGBMClassifier(objective='binary', random_state = 1)\n",
    "\n",
    "lgbmc_param = {'n_estimators':[100,200,500,1000],\n",
    "               'metric': ['auc', 'binary_logloss'],\n",
    "               'num_leaves': [10,31,50],\n",
    "               'learning_rate':[0.01, 0.1],\n",
    "               'min_data_in_leaf': [20, 30, 50, 100],}\n",
    "\n",
    "lgbmc_grid = GridSearchCV(estimator=lgbmc, param_grid=lgbmc_param, cv = 2, scoring = 'accuracy', n_jobs = -2)\n",
    "\n",
    "# Fit the model\n",
    "lgbmc_grid.fit(X_trainS, y_train)\n",
    "# rmse for regression, and logloss for classification, mean average precision for ranking\n",
    "\n",
    "# Prediction\n",
    "print(\"\\nBest params:\",lgbmc_grid.best_params_)\n",
    "print(\"\\nAccuracy tuned LGBM\",np.mean(lgbmc_grid.predict(X_testS) == y_test))\n",
    "\n",
    "\n",
    "# https://www.kaggle.com/garethjns/microsoft-lightgbm-with-parameter-tuning-0-823"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:** Light GBM gives good result of 0.852 with hyper parameter tuning yet overall XGBoost gave best result of 0.853 accuracy score, though all other boosting scores are comparable too. Maybe with more hyperparameter tuning the results can improve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking\n",
    "Lastly, let's do this with Stacking.  \n",
    "Using the same models from the voting classifiers.  \n",
    "Using Random Forest as blender function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use as many boxes as you need\n",
    "models = {'lr1_unreg': clf1, 'lr2_reg': clf2, 'rf': clf3, 'gb': clf4, 'knn': clf5}\n",
    "\n",
    "# Also define the blender\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "blender= RandomForestClassifier(random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training data into two parts, one to train the weak learners, another to train the blender\n",
    "X_trainS1, X_trainS2, y_train1, y_train2 = train_test_split(X_trainS, y_train, test_size = 0.5, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the weak learners\n",
    "for name, model in models.items():\n",
    "    model.fit(X_trainS1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the blender\n",
    "# Get the prediction\n",
    "predictions = pd.DataFrame() # Set up a dataframe to store the predictions\n",
    "for name, model in models.items():\n",
    "    predictions[name] = model.predict_proba(X_trainS2)[:,1] # Taking probability of positive class in binary classification\n",
    "\n",
    "# Get the blender\n",
    "scaler_blend = StandardScaler() # Scale the predictions \n",
    "predictions_scale = scaler_blend.fit_transform(predictions)\n",
    "blender.fit(predictions_scale, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.851"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform evaluation\n",
    "# First send the data through the weak learners\n",
    "predictions = pd.DataFrame() # Set up a dataframe to store the predictions\n",
    "for name, model in models.items():\n",
    "    predictions[name] = model.predict_proba(X_testS)[:,1] # Taking probability of positive class in binary classification\n",
    "    \n",
    "# Prediction through the blender, and evaluate\n",
    "predictions_scale = scaler_blend.transform(predictions)\n",
    "#np.sqrt(mean_squared_error(blender.predict(predictions_scale), y_test))\n",
    "np.mean(blender.predict(predictions_scale) == y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:** Stacking accuracy(0.851) is somewhat close and comparable to LGBM results(0.852). \n",
    "Overall, Boosting shows highest accuracy and Bagging shows the least.\n",
    "Individually, Random Forest accuracy score is the highest overall at 0.8535. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
